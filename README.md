## Project Structure
â€â€â€
â”œâ”€â”€ assets/              # Screenshots and media
â”œâ”€â”€ data/                # Kaggle data instructions
â”œâ”€â”€ models/              # Saved XGBoost models / MLflow artifacts
â”œâ”€â”€ notebooks/           # EDA and LSTM experiments
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ training.py
â”‚   â”œâ”€â”€ lstm_colab.py
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
â€â€â€
## Datenhinweis

Die OriginaldatensÃ¤tze sind aufgrund ihrer GrÃ¶ÃŸe nicht im GitHub-Repository enthalten.
Bitte lade die Daten vom Kaggle-Wettbewerb â€Favorita Grocery Sales Forecastingâ€œ herunter:
https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting

Speichere die CSV-Dateien anschlieÃŸend im Ordner /data, damit die Skripte korrekt ausgefÃ¼hrt werden kÃ¶nnen.

## Einzelhandelsnachfrageanalyse
In diesem Projekt wird die tÃ¤gliche Nachfrage (unit_sales) fÃ¼r Einzelhandelsprodukte in der Region Guayas auf Basis des Kaggle-Datensatzes â€CorporaciÃ³n Favoriteâ€œ prognostiziert. Der Fokus liegt auf Datenaufbereitung, Feature Engineering sowie dem Vergleich eines XGBoost-Baselinemodells mit einem LSTM-Ansatz.

## Nachfrageprognose fÃ¼r den Einzelhandel â€“ Guayas (Woche 2)
## Ziel
Prognose der tÃ¤glichen Verkaufsmenge ( unit_sales) fÃ¼r Stores in der Region Guayas auf Basis vorbereiteter Zeitreihendaten (Q1 2014).

## Daten
Region: Guayas
Produktfamilien: LEBENSMITTEL I, GETRÃ„NKE, REINIGUNG
Zeitraum: 01.01.2014 â€“ 31.03.2014
Zielvariable: StÃ¼ckverkÃ¤ufe
Modell
Modell: XGBoost-Regressor
Features: Kalendermerkmale, Lags, Rolling Mean, Store- & Item-Metadaten
Zug/Test: Janâ€“Feb / MÃ¤rz (chronologisch)
Ergebnisse
MAE: 340,34
RMSE: 360,02
Kurzfristige Lags (lag_1) dominieren die Prognose
Kalender- und Store-Effekte unterstÃ¼tzt
Reflexion â€“ Woche 2 (Guayas, XGBoost)
Diese Woche wurde auf Basis der in Woche 1 vorbereiteten Guayas-Daten (Top-3-Produktfamilien: LEBENSMITTEL I, GETRÃ„NKE, REINIGUNG) ein erstes Prognosemodell erstellt. Der Analysezeitraum wurde auf das erste Quartal 2014 (01.01.â€“31.03.) begrenzt und chronologisch in Trainingsdaten (Januar/Februar) und Testdaten (MÃ¤rz) unterteilt, um Datenlecks zu vermeiden.

Das Feature Engineering umfasst Kalendermerkmale (Wochentag, Monat, Wochenende) sowie zeitliche Merkmale wie Lag-Features und Rolling Means. Das XGBoost-Modell stellte eine funktionierende Baseline dar, zeigte jedoch Grenzen aufgrund intermittierender VerkÃ¤ufe (viele Nullen und seltene Peaks) sowie der starken Reduzierung des Datenausschnitts. In der Feature-Importance dominierten kurzfristige Signale (z. B. lag_1) und statische Artikel- bzw. Filialmerkmale, wÃ¤hrend Promotions und rollierende Mittelwerte in diesem Setup nur begrenzte Zusatznutzen lieferten.

## Fazit: 
Die Pipeline ist korrekt und reproduzierbar. FÃ¼r realistischere Nachfrageprognosen auf Item-Ebene wÃ¤ren jedoch dichtere Zeitreihen (z. B. AuffÃ¼llen fehlender Tage) oder alternative Modellierungsebenen und -ansÃ¤tze besser geeignet.

Zur zusÃ¤tzlichen Analyse der zeitlichen AbhÃ¤ngigkeiten wurde ein Autokorrelationsdiagramm (ACF) der aggregierten TagesumsÃ¤tze fÃ¼r Guayas (Q1 2014) erstellt. Das Diagramm zeigte eine deutliche kurzfristige Autokorrelation (Lag 1) sowie Hinweise auf eine wÃ¶chentliche Struktur (Lag 7), was die Verwendung von Lag-Features grundsÃ¤tzlich rechtfertigt. Gleichzeitig nahm die Autokorrelation schnell ab, was auf eine hohe VariabilitÃ¤t und unregelmÃ¤ÃŸige Nachfrage auf Item-Ebene hinwies. Dies erklÃ¤rt, warum einfache Lag-Features im Modell vorherrschen, wÃ¤hrend komplexere rollierende Features nur begrenzte Zusatznutzenlieferten.

## NÃ¤chste Schritte / Verbesserungen
Zeitreihen verdichten: FÃ¼r jede (store_nbr, item_nbr)-Kombination einen vollstÃ¤ndigen Tagesindex erzeugen und fehlende Tage mit unit_sales=0 auffÃ¼llen, damit lag_7 und roll_mean_7 informativ werden.

Aggregation testen: Prognose auf StoreÃ—Family-Ebene (statt StoreÃ—Item) als stabilere Zwischenstufe vergleichen.

Funktionen erweitern: Feiertage, Ã–lpreis, Transaktionen und Promotion-IntensitÃ¤t (z. B. Promo-Anteil pro Woche) integrieren.

Zieltransformation: log1p(unit_sales) testen, um Peaks abzumildern.

## Modellvergleich: Alternativen wie HistGradientBoostingRegressor (sklearn), LightGBM (optional) oder LSTM/GRU (Bonus) ausprobieren und MAE/RMSE vergleichen.

Zur Validierung der zeitlichen AbhÃ¤ngigkeiten wurde ein ACF-Plot der differenzierten TagesumsÃ¤tze erstellt. Signifikante Autokorrelationen bei Lag 7 und Vielfachen bestÃ¤tigen eine wÃ¶chentliche SaisonalitÃ¤t und rechtfertigen die Verwendung von Lag- und Rolling-Features im XGBoost-Modell.

## Optional: LSTM-Modell (konzeptioneller Vergleich)
Ein LSTM-Modell wurde als alternative Zeitreihenmethode in Betracht gezogen, da es sequenzielle AbhÃ¤ngigkeiten explizit modellieren kann und insbesondere bei dichten Zeitreihen Vorteile bietet. FÃ¼r den vorliegenden Datenausschnitt (Guayas, Q1 2014) ist die Nachfrage auf Item-Ebene jedoch stark intermittierend, was eine Aggregation (z. B. StoreÃ—Family) fÃ¼r LSTM-Modelle erforderlich machen wÃ¼rde.

Eine praktische Implementierung wurde im Rahmen dieses Projekts nicht durchgefÃ¼hrt, da die verwendete Python-Version (3.14) aktuell nicht von TensorFlow unterstÃ¼tzt wird. Konzeptionell wÃ¤re ein LSTM insbesondere auf aggregierter Ebene (z. B. tÃ¤gliche VerkÃ¤ufe pro Produktfamilie) sinnvoll und kÃ¶nnte in zukÃ¼nftiger Arbeit mit geeigneter Umgebung evaluiert werden.

Im Vergleich dazu eignet sich XGBoost besser als robuste Baseline fÃ¼r sparse tabellarische Zeitreihendaten mit vielen erklÃ¤renden Variablen.

â€Alternativ wÃ¤re eine Implementierung mit PyTorch mÃ¶glich gewesen, da dieses Framework neue Python-Versionen schneller unterstÃ¼tzt. Dies liegt jedoch auÃŸerhalb des Umfangs dieser Aufgabe.â€œ

In Colab Mini Modell erstellt:

## ğŸ“Œ Ergebniszusammenfassung LSTM
FÃ¼r die Region Guayas wurde zusÃ¤tzlich ein LSTM-Modell auf aggregierter Ebene trainiert. Die tÃ¤glichen KÃ¤ufe wurden pro Produktfamilie zusammengefasst und fÃ¼r das erste Quartal 2014 modelliert. FÃ¼r die Familie GROCERY I gab sich ein MAE von 340 und ein RMSE von 360. Die vergleichsweise hohen Fehlerwerte sind auf die Aggregation Ã¼ber alle Stores und Artikel zurÃ¼ckzufÃ¼hren und liegen im realistischen Bereich der tÃ¤glichen GesamtverkÃ¤ufe.

## ğŸ§  Kurze Einordnung / Vergleich
Im Vergleich zum XGBoost-Modell auf Store-Item-Ebene ist das LSTM-Modell weniger prÃ¤zise, â€‹â€‹da es auf einer deutlich grÃ¶ÃŸeren Aggregation und mit wenigen Eingangsmerkmalen trainiert wurde. Das Experiment zeigt jedoch, dass LSTM-Modelle grundsÃ¤tzlich fÃ¼r aggregierte Nachfrageprognosen geeignet sind, bei kurzen Zeitreihen jedoch limitiert bleiben.

## Reflexion â€“ Woche 3
In Woche 3 wurde auf Basis der Q1-2014-Daten fÃ¼r Guayas ein XGBoost-Modell trainiert und mit MLflow systematisch evaluiert. Durch einen streng chronologischen Train-/Test-Split konnten realistische Prognosefehler berechnet werden.

Die Ergebnisse zeigen, dass XGBoost gegenÃ¼ber der Baseline eine Verbesserung erzielt, insbesondere in MAE und RMSE. Gleichzeitig fÃ¤llt der MAPE aufgrund stark intermittierender Nachfrage auf Item-Ebene sehr hoch aus, was die eingeschrÃ¤nkte Eignung prozentualer FehlermaÃŸe in diesem Kontext verdeutlicht.

Die Analyse unterstreicht, dass Nachfrageprognosen auf aggregierter Ebene (z. B. Store Ã— Familie) deutlich stabiler und besser modellierbar sind, wÃ¤hrend Item-Level-Forecasts spezielle AnsÃ¤tze wie Croston erfordern. Insgesamt liefert das Projekt eine saubere, reproduzierbare Forecasting-Pipeline und ein realistisches VerstÃ¤ndnis der Grenzen datengetriebener Nachfrageprognosen.

## ğŸ—“ï¸  â€“ Streamlit-App
## Ziel
Businesstaugliche OberflÃ¤che

Planer kÃ¶nnen:

Filiale wÃ¤hlen

SKU oder Familie auswÃ¤hlen

Zeitraum wÃ¤hlen

Wettervorhersage

CSV-Export

Warum Streamlit?

schnell entwickelt

wenig Code

Ideal fÃ¼r Data Science Prototypen

sofort visuell

## ğŸ¯ Zentrale Erkenntnisse
Retail-Daten sind oft zeitweilig

Aggregation stabilisiert Prognosen

Boosting-Modelle schlagen Deep Learning bei kleinen/sparse DatensÃ¤tzen

MLflow verbessert die Reproduzierbarkeit stark

Streamlit eignet sich ideal fÃ¼r schnelle Deployment-Demos

## ğŸ§  Technische Besonderheiten
## Warum XGBoost?
Beste Performance auf tabellarischen Daten

Warum LSTM nur Colab?

TensorFlow unterstÃ¼tzt Python 3.14 noch nicht

Warum keine reinen Zeitreihenmodelle?

Zu viele parallele Serien + LÃ¼cken

Warum Aggregation sinnvoll?

Stabilere Signale

## ğŸ¤ Kurzfazit
Es wurde eine reproduzierbare Demand-Forecasting-Pipeline mit XGBoost als robustem Baseline-Modell aufgebaut. Ein zusÃ¤tzlicher LSTM-Vergleich wurde aufgrund von TensorFlow-KompatibilitÃ¤t in Colab trainiert, jedoch auf sparse Retail-Daten geringerer Genauigkeit. Die Ergebnisse wurden Ã¼ber MLflow versioniert und in einer Streamlit-App interaktiv bereitgestellt.





Meine persÃ¶nlichen Daten dÃ¼rfen nicht weitergegeben werden.
