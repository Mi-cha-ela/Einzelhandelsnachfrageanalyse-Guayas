# Einzelhandelsnachfrageanalyse-Guayas
In diesem Projekt wird die t√§gliche Nachfrage (unit_sales) f√ºr Einzelhandelsprodukte in der Region Guayas auf Basis des Kaggle-Datensatzes ‚ÄûCorporaci√≥n Favorita‚Äú prognostiziert. Der Fokus liegt auf Datenaufbereitung, Feature Engineering sowie dem Vergleich eines XGBoost-Baselinemodells mit einem LSTM-Ansatz.

## Datenhinweis

Die Originaldatens√§tze sind aufgrund ihrer Gr√∂√üe nicht im GitHub-Repository enthalten.
Bitte lade die Daten vom Kaggle-Wettbewerb ‚ÄûFavorita Grocery Sales Forecasting‚Äú herunter:
https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting

Speichere die CSV-Dateien anschlie√üend im Ordner /data, damit die Skripte korrekt ausgef√ºhrt werden k√∂nnen.

Einzelhandelsnachfrageanalyse
In diesem Projekt wird die t√§gliche Nachfrage (unit_sales) f√ºr Einzelhandelsprodukte in der Region Guayas auf Basis des Kaggle-Datensatzes ‚ÄûCorporaci√≥n Favorite‚Äú prognostiziert. Der Fokus liegt auf Datenaufbereitung, Feature Engineering sowie dem Vergleich eines XGBoost-Baselinemodells mit einem LSTM-Ansatz.

Nachfrageprognose f√ºr den Einzelhandel ‚Äì Guayas (Woche 2)
Ziel
Prognose der t√§glichen Verkaufsmenge ( unit_sales) f√ºr Stores in der Region Guayas auf Basis vorbereiteter Zeitreihendaten (Q1 2014).

## Daten
Region: Guayas
Produktfamilien: LEBENSMITTEL I, GETR√ÑNKE, REINIGUNG
Zeitraum: 01.01.2014 ‚Äì 31.03.2014
Zielvariable: St√ºckverk√§ufe
Modell
Modell: XGBoost-Regressor
Features: Kalendermerkmale, Lags, Rolling Mean, Store- & Item-Metadaten
Zug/Test: Jan‚ÄìFeb / M√§rz (chronologisch)
Ergebnisse
MAE: XX.X
RMSE: XX,X
Kurzfristige Lags (lag_1) dominieren die Prognose
Kalender- und Store-Effekte unterst√ºtzt
Reflexion ‚Äì Woche 2 (Guayas, XGBoost)
Diese Woche wurde auf Basis der in Woche 1 vorbereiteten Guayas-Daten (Top-3-Produktfamilien: LEBENSMITTEL I, GETR√ÑNKE, REINIGUNG) ein erstes Prognosemodell erstellt. Der Analysezeitraum wurde auf das erste Quartal 2014 (01.01.‚Äì31.03.) begrenzt und chronologisch in Trainingsdaten (Januar/Februar) und Testdaten (M√§rz) unterteilt, um Datenlecks zu vermeiden.

Das Feature Engineering umfasst Kalendermerkmale (Wochentag, Monat, Wochenende) sowie zeitliche Merkmale wie Lag-Features und Rolling Means. Das XGBoost-Modell stellte eine funktionierende Baseline dar, zeigte jedoch Grenzen aufgrund intermittierender Verk√§ufe (viele Nullen und seltene Peaks) sowie der starken Reduzierung des Datenausschnitts. In der Feature-Importance dominierten kurzfristige Signale (z. B. lag_1) und statische Artikel- bzw. Filialmerkmale, w√§hrend Promotions und rollierende Mittelwerte in diesem Setup nur begrenzte Zusatznutzen lieferten.

## Fazit: Die Pipeline ist korrekt und reproduzierbar. F√ºr realistischere Nachfrageprognosen auf Item-Ebene w√§ren jedoch dichtere Zeitreihen (z. B. Auff√ºllen fehlender Tage) oder alternative Modellierungsebenen und -ans√§tze besser geeignet.

Zur zus√§tzlichen Analyse der zeitlichen Abh√§ngigkeiten wurde ein Autokorrelationsdiagramm (ACF) der aggregierten Tagesums√§tze f√ºr Guayas (Q1 2014) erstellt. Das Diagramm zeigte eine deutliche kurzfristige Autokorrelation (Lag 1) sowie Hinweise auf eine w√∂chentliche Struktur (Lag 7), was die Verwendung von Lag-Features grunds√§tzlich rechtfertigt. Gleichzeitig nahm die Autokorrelation schnell ab, was auf eine hohe Variabilit√§t und unregelm√§√üige Nachfrage auf Item-Ebene hinwies. Dies erkl√§rt, warum einfache Lag-Features im Modell vorherrschen, w√§hrend komplexere rollierende Features nur begrenzte Zusatznutzenlieferten.

## N√§chste Schritte / Verbesserungen
Zeitreihen verdichten: F√ºr jede (store_nbr, item_nbr)-Kombination einen vollst√§ndigen Tagesindex erzeugen und fehlende Tage mit unit_sales=0 auff√ºllen, damit lag_7 und roll_mean_7 informativ werden.

Aggregation testen: Prognose auf Store√óFamily-Ebene (statt Store√óItem) als stabilere Zwischenstufe vergleichen.

Funktionen erweitern: Feiertage, √ñlpreis, Transaktionen und Promotion-Intensit√§t (z. B. Promo-Anteil pro Woche) integrieren.

Zieltransformation: log1p(unit_sales) testen, um Peaks abzumildern.

## Modellvergleich: Alternativen wie HistGradientBoostingRegressor (sklearn), LightGBM (optional) oder LSTM/GRU (Bonus) ausprobieren und MAE/RMSE vergleichen.

Zur Validierung der zeitlichen Abh√§ngigkeiten wurde ein ACF-Plot der differenzierten Tagesums√§tze erstellt. Signifikante Autokorrelationen bei Lag 7 und Vielfachen best√§tigen eine w√∂chentliche Saisonalit√§t und rechtfertigen die Verwendung von Lag- und Rolling-Features im XGBoost-Modell.

## Optional: LSTM-Modell (konzeptioneller Vergleich)
Ein LSTM-Modell wurde als alternative Zeitreihenmethode in Betracht gezogen, da es sequenzielle Abh√§ngigkeiten explizit modellieren kann und insbesondere bei dichten Zeitreihen Vorteile bietet. F√ºr den vorliegenden Datenausschnitt (Guayas, Q1 2014) ist die Nachfrage auf Item-Ebene jedoch stark intermittierend, was eine Aggregation (z. B. Store√óFamily) f√ºr LSTM-Modelle erforderlich machen w√ºrde.

Eine praktische Implementierung wurde im Rahmen dieses Projekts nicht durchgef√ºhrt, da die verwendete Python-Version (3.14) aktuell nicht von TensorFlow unterst√ºtzt wird. Konzeptionell w√§re ein LSTM insbesondere auf aggregierter Ebene (z. B. t√§gliche Verk√§ufe pro Produktfamilie) sinnvoll und k√∂nnte in zuk√ºnftiger Arbeit mit geeigneter Umgebung evaluiert werden.

Im Vergleich dazu eignet sich XGBoost besser als robuste Baseline f√ºr sparse tabellarische Zeitreihendaten mit vielen erkl√§renden Variablen.

# #‚ÄûAlternativ w√§re eine Implementierung mit PyTorch m√∂glich gewesen, da dieses Framework neue Python-Versionen schneller unterst√ºtzt. Dies liegt jedoch au√üerhalb des Umfangs dieser Aufgabe.‚Äú

## In Colab Mini Modell erstellt:

## üìå Ergebniszusammenfassung LSTM
F√ºr die Region Guayas wurde zus√§tzlich ein LSTM-Modell auf aggregierter Ebene trainiert. Die t√§glichen K√§ufe wurden pro Produktfamilie zusammengefasst und f√ºr das erste Quartal 2014 modelliert. F√ºr die Familie GROCERY I gab sich ein MAE von 340 und ein RMSE von 360. Die vergleichsweise hohen Fehlerwerte sind auf die Aggregation √ºber alle Stores und Artikel zur√ºckzuf√ºhren und liegen im realistischen Bereich der t√§glichen Gesamtverk√§ufe.

üß† Kurze Einordnung / Vergleich
Im Vergleich zum XGBoost-Modell auf Store-Item-Ebene ist das LSTM-Modell weniger pr√§zise, ‚Äã‚Äãda es auf einer deutlich gr√∂√üeren Aggregation und mit wenigen Eingangsmerkmalen trainiert wurde. Das Experiment zeigt jedoch, dass LSTM-Modelle grunds√§tzlich f√ºr aggregierte Nachfrageprognosen geeignet sind, bei kurzen Zeitreihen jedoch limitiert bleiben.

Reflexion ‚Äì Woche 3
In Woche 3 wurde auf Basis der Q1-2014-Daten f√ºr Guayas ein XGBoost-Modell trainiert und mit MLflow systematisch evaluiert. Durch einen streng chronologischen Train-/Test-Split konnten realistische Prognosefehler berechnet werden.

Die Ergebnisse zeigen, dass XGBoost gegen√ºber der Baseline eine Verbesserung erzielt, insbesondere in MAE und RMSE. Gleichzeitig f√§llt der MAPE aufgrund stark intermittierender Nachfrage auf Item-Ebene sehr hoch aus, was die eingeschr√§nkte Eignung prozentualer Fehlerma√üe in diesem Kontext verdeutlicht.

Die Analyse unterstreicht, dass Nachfrageprognosen auf aggregierter Ebene (z. B. Store √ó Familie) deutlich stabiler und besser modellierbar sind, w√§hrend Item-Level-Forecasts spezielle Ans√§tze wie Croston erfordern. Insgesamt liefert das Projekt eine saubere, reproduzierbare Forecasting-Pipeline und ein realistisches Verst√§ndnis der Grenzen datengetriebener Nachfrageprognosen.

## üóìÔ∏è  ‚Äì Streamlit-App
## Ziel
Businesstaugliche Oberfl√§che

Planer k√∂nnen:

Filiale w√§hlen

SKU oder Familie ausw√§hlen

Zeitraum w√§hlen

Wettervorhersage

CSV-Export

Warum Streamlit?

schnell entwickelt

wenig Code

Ideal f√ºr Data Science Prototypen

sofort visuell

## üéØ Zentrale Erkenntnisse
Retail-Daten sind oft zeitweilig

Aggregation stabilisiert Prognosen

Boosting-Modelle schlagen Deep Learning bei kleinen/sparse Datens√§tzen

MLflow verbessert die Reproduzierbarkeit stark

Streamlit eignet sich ideal f√ºr schnelle Deployment-Demos

üß† Technische Besonderheiten
Warum XGBoost?
Beste Performance auf tabellarischen Daten

Warum LSTM nur Colab?

TensorFlow unterst√ºtzt Python 3.14 noch nicht

Warum keine reinen Zeitreihenmodelle?

Zu viele parallele Serien + L√ºcken

Warum Aggregation sinnvoll?

Stabilere Signale

üé§ Kurzfazit
Es wurde eine reproduzierbare Demand-Forecasting-Pipeline mit XGBoost als robustem Baseline-Modell aufgebaut. Ein zus√§tzlicher LSTM-Vergleich wurde aufgrund von TensorFlow-Kompatibilit√§t in Colab trainiert, jedoch auf sparse Retail-Daten geringerer Genauigkeit. Die Ergebnisse wurden √ºber MLflow versioniert und in einer Streamlit-App interaktiv bereitgestellt.





Meine pers√∂nlichen Daten d√ºrfen nicht weitergegeben werden.
